### 数据不安全的现象，队列，池以及协程的应用

#### 1.数据存在不安全的现象，以及死锁现象

```python
if,while,+=,-=,*=,/=在线程中都会出现数据不安全，这是在底层考虑的，从CPU置零进行思考。（需要加锁）
多个线程同时操作全局变量/静态变量，就会产生数据不安全现象
RLock 递归锁，效率没有互斥锁高，而且90%的问题互斥锁都可以解决


死锁现象：在有多把锁且交叉使用就会出现死锁现象（如果是递归锁，可以将多把锁改为一把锁，就可以解决，互斥锁改为递归锁并改为一把锁，也可以解决，但是程序的效率会有所降低）（最好方式是使用互斥锁并改为一把锁，但是用递归锁可以快速解决，有奇效）
```

+ ##### 递归锁

```python
from threading import RLock
rlock=RLock()
with rlock:
    pass
rlock.acquire()
rlock.acquire()
print(666)
rlock.release()
rlock.release()
#递归锁，正如它的名字，可以多次进行acquire，相当于门里还有门，当然其他的线程要想拿到钥匙，必须要将拿到钥匙的线程退到最后一层。
```

#### 2.队列

+ ##### 队列分为三种，队列，栈，以及优先队列

```python
from queue import Queue,LifoQueue,PriorityQueue
q=Queue()	#队列，先进先出
q1=LifoQueue()	#栈，先进后出
q2=PriorityQueue()	#

q.put()
q.get()
q1.put()
q1.get()
q2.put((3,'alex'))
q2.put((2,'taibai'))		#按这种方式赋值，会按照第一个元素的ASCII码进行排序，get的时候按照序号的先后进行输出，同一个等级按照队列先入先出
q2.get()
```

#### 3.池

+ ##### 池就是提前开好的线程或者是进程，这样就不用直接在循环中开线程或者进程了，可以控制进程数以及线程数

```python
def func(num,name):
    print(num,name,666)

from concurrent.futures import ThreadPoolExecutor,ProcessPoolExecutor
tl=ThreadPoolExecutor(20)	#开了20个进程
# for i in range(200):
#     tl.submit(func,'a')	#这是一种提交任务的方式，提交了两百个相同的任务
tl.map(func,range(5)[1:],['lxc','taibai','lxc','lxc'])
#这是另一种提交方式，第一个参数是函数的名称，后面的参数就是函数所需的参数，会按照先后顺序，将参数放入函数中
```

+ ##### 这里需要注意的就是对于进程，我们可以开到CPU数+1，对于线程数，我们可以开到CPU数*5，对于我的4核电脑，进程开到5，线程开到20也就是说，最大的异步情况是100，更大的异步的情况就需要开协程了

```python
tp=[]
for i in range(200):
    ret=tl.submit(func,'a')
    tp.append(ret)
    #对于tp中存储的数据，为future对象，这里说一下对于future对象的理解，我人为future类似于一种占位符的存在，当函数没有执行完成时，就在列表中站一个为，说明这里是有数据的，如果要进行操作就需要进行阻塞，等函数执行完成拿到相应的数据后再进行操作。这也就说明了为什么叫future对象，是一种未来才会使用到的数据。
```

+ ##### 回调函数

##### 在某一个线程执行完成后，立刻进行某种操作

```python
def func(num,name):
    # print(num,name,666)
    return num
def ff(num):
    print(num)

for i in range(200):
    ret=tl.submit(func,'a')
    ret.add_done_callback(ff)	#对future对象应用，在拿到某个值后立刻调用ff函数
```

#### 4.协程

+ ##### 定义

```python
（正常的开发语言，多线程可以利用多核，cpython解释器下的多线程不能利用多核，相当于规避了所有io操作的单线程），协程对操作系统是不可见的。协程本质就是一条线程，多个任务在一条线程上来回切换，来规避IO操作，就达到了我们将一条线程中的io操作降到最低的目的
```

+ ##### `asyncio`

```python
import asyncio

async def func():  
    #async标识这个函数是协程函数
    print('start')
    await asyncio.sleep(1) 
    #必须加上await
    print('end')

loop=asyncio.get_event_loop()		#这里是循环判断什么时候该切回去
loop.run_until_complete(asyncio.wait([func(),func()]) )#个人感觉协程开的多得用列表推导式
#loop.run_until_complete(func() )	#这里如果只开一个协程就直接这么写就行
        #协程
```

+ ##### `grevent`

```python
from gevent import monkey		#这个一定要写在上面
import gevent
monkey.patch_all()		#这里相当于把要调用的函数改为语法糖（弹幕的理解，我认为也是这样）
import time	

def func():
    print('start func')
    time.sleep(1)
    print('end func')

g1=gevent.spawn(func)		#提交任务
g2=gevent.spawn(func)
g3=gevent.spawn(func)
gevent.joinall([g1,g2,g3])	#等待各个协程结束
#或者g1.join()
```